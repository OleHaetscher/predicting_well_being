general:
  datasets_to_be_included: [cocoesm] # , cocout, cocoms, emotions, pia, zpid]  # cocoesm, cocoms, cocout, emotions, pia, zpid
  log_dir: "../logs/final_tests_analysis"
  log_name: 01092024

  steps:
    preprocessing: true
    analysis: false
    postprocessing: false

preprocessing:
  path_to_raw_data: "../data/raw"
  store_data: false
  path_to_preprocessed_data: "../data/preprocessed"
  min_num_esm_measures: 5  # 5
  nrows: 99999
  need_inverse_coding: ["cocout", "emotions", "pia", "zpid", "cocoms"]  # all except cocoesm, do not change
  # joint id col -> ID is the index in every dataset
  sanity_checking:
    nan_thresh: 0.3 # 30% NaNs -> warn
    cron_alpha_thresh: 0.6
    expected_pos_corrs:
    - self_esteem
    - social_status
    - trust_government
    - education_level
    - state_pa
    - trait_pa
    - sleep_quality_mean
    - number_interactions_mean
    - gdp_capita
    - state_wb
    - creative_imagination
    - productiveness
    - responsibility


    number_of_features:  # as in PreReg Table, without sensing ye
      cocoesm: 149 # inklusive 6x wb, davon MAC 54
      cocoms: 96 # inklusive 6x wb, number_interactions / percentage_interactions + unique_id / studyWave
      cocout: 73 # inklusive 6x wb, studyWave
      emotions: 56 # inklusive 3x wb + "living_alone"
      pia: 42  # inklusive 6x wb
      zpid: 67 # inklusive 4x wb

analysis:
  load_data: true
  path_to_preprocessed_data: "../data/preprocessed"
  random_state: 42

  methods_to_apply:
    - select_samples
    - select_features
    - select_criterion
    - initial_info_log
    - create_pipeline
    - repeated_nested_cv
    - get_average_coefficients
    - store_analysis_results  # CAUTION

# for each combination, we will also use all samples and always compare it against the same samples using only pl
  feature_sample_combinations:
    # 1
    pl: [emotions, cocout, cocoesm, cocoms]
    srmc: [emotions, cocout, cocoesm, cocoms]
    sens: [zpid, cocoms]
    srmc_sens: [cocoms]
    mac: [cocoesm]
    # 2  filter for "pl_" for comparisons
    pl_srmc: [emotions, cocout, cocoesm, cocoms]
    pl_sens: [zpid, cocoms]
    pl_srmc_sens: [cocoms]
    pl_mac: [cocoesm]
    # 3
    pl_srmc_mac: [cocoesm]
    # 4 all_in
    all_in: [cocoesm, cocout, cocoms, emotions, pia, zpid]

  params: # adjusted by SLURM
    prediction_model: elasticnet  # elasticnet, randomforestregressor
    crit: state_wb  # state_wb, state_pa, state_na, trait_wb, trait_na, trait_pa
    feature_combination: srmc  # pl, srmc, sens, mac, pl_srmc, pl_sens, pl_srmc_sens, pl_mac, pl_srmc_mac, all
    samples_to_include: selected  # all, selected, control

  cv:
    num_inner_cv: 3  # 10
    verbose_inner_cv: 0  #
    num_outer_cv: 3  # 10
    num_reps: 2  # 10
    id_grouping_col: other_unique_id

  crit_available: # not all criteria are available for all samples
    state_wb: [cocoesm, cocout, cocoms, emotions, pia, zpid]
    state_pa: [cocoesm, cocout, cocoms, emotions, pia]
    state_na: [cocoesm, cocout, cocoms, emotions, pia]
    trait_wb: [cocoesm, cocout, cocoms, pia, zpid]
    trait_pa: [cocoesm, cocout, cocoms, pia, zpid]
    trait_na: [cocoesm, cocout, cocoms, pia, zpid]

  imputation:
    num_imputations: 2  # 5
    max_iter: 3  # 100

  scoring_metric:  # TODO: Check
    inner_cv_loop:
      name: neg_mean_squared_error
    outer_cv_loop: # only for evaluation in the outer loop, not for fitting, all tested
      - r2
      - neg_mean_squared_error
      - spearman

  model_hyperparameters:
    elasticnet:  # verify
      model__regressor__alpha: [0.1, 1]
      model__regressor__l1_ratio: [0, 1]
      # model__alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]
      # model__l1_ratio: [0, 0.1, 0.2, 0.3, 0.4, 0.4, 0.6, 0.7, 0.8, 0.9, 1]
      # model__max_iter: [ 1000, 10000 ]
      # model__tol: [0.1, 0.01, 0.001, 0.0001]
    randomforestregressor:
      model__regressor__n_estimators: [ 10 ]
      model__regressor__max_depth: [2, 5]
      # model__n_estimators: [ 100, 1000 ]
      # model__max_features: [ 'sqrt', 0.25, 0.5, 0.75 ]
      # model__max_depth: [2, 4, 6, 8, 10, 15, 20, 25]
      # model__min_samples_split: [2, 4, 6, 8, 10, 15, 20, 25]

  parallelize:
    parallelize_shap: true
    shap_n_jobs: 1
    parallelize_inner_cv: true
    inner_cv_n_jobs: 1
    parallelize_shap_ia_values: true
    shap_ia_values_n_jobs: 1
    parallelize_imputations: true
    imputations_n_jobs: 1  # TODO: Caution with RFR imputation model, test further

  shap_ia_values:  # TODO Needs to be implemented based on our affordances
    comp_shap_ia_values: false
    min_order: 2  # min interaction order, we already got 1 (the normal SHAP values)
    max_order: 3  # max interaction order, one correspond to the normal SHAP values
    budget: x  # budget for computation


  output_path: "../results/ml_analysis"
  output_filenames:
    performance: 'cv_results.json'
    shap_values: 'shap_values.pkl'  # contains shap_values, base_values, and data
    shap_ia_values: 'shap_ia_values.pkl'
    lin_model_coefs: 'lin_model_coefficients.json'

postprocessing:
  significance_testing:
    output_path: "../results/significance_tests"
    alpha:
    metric: r2
    methods:
      - xxx




