general:
  datasets_to_be_included: [  cocoesm, cocoms, cocout, emotions, pia, zpid ] # cocoesm, cocoms, cocout, emotions, pia, zpid
  log_dir: "../logs/new_data_2811"  # only for preprocessing, analysis logs are stored in the result folders
  log_name: x

  steps:
    preprocessing: false
    analysis: true
    postprocessing: false

preprocessing:
  path_to_raw_data: "../data/raw"
  store_data: true  # stores the full preprocessed df
  path_to_preprocessed_data: "../data/preprocessed"
  min_num_esm_measures: 5  # 5
  nrows: 999999 # only for descriptives
  need_inverse_coding: ["cocout", "emotions", "pia", "zpid", "cocoms"]  # all except cocoesm, do not change

  esm_id_col:
    cocoesm: participant
    cocoms: original_id
    cocout: id
    emotions: id
    pia: id
    zpid: user_id

  esm_timestamp_col:
    emotions: created_esm
    zpid: questionnaireStartedTimestamp_corrected
    cocout: StartDateConvert_esm
    pia: created
    cocoesm: created_individual_esm
    cocoms: questionnaireStartedTimestamp

  years_of_data_collection:
    cocoesm: [ 2021, 2022]
    cocoms: [ 2022, 2023]
    zpid: [ 2020 ]
    emotions: [ 2020 ]
    cocout: [ 2020, 2021 ]
    pia: [ 2021 ]

  sensing:
    app_substring:
      cocoms: "App_"
      zpid: "app_"
    call_substring:
      cocoms: "Call_totalDur"
      zpid: "phone_sum_dur_calls"
    call_reference:
      cocoms: "Screen_totalDur_unlocked"
      zpid: "screen_sum_dur_session"

  sanity_checking:
    sensing:
      nan_col_thresh: 0.15
      zero_col_thresh: 0.30

    nan_thresh: 0.3 # 30% NaNs -> warn
    cron_alpha_thresh: 0.6
    expected_pos_corrs:
    - self_esteem
    - social_status
    - trust_government
    - education_level
    - state_pa
    - trait_pa
    - trait_na
    - sleep_quality_mean
    - number_interactions_mean
    - gdp_capita
    - state_wb
    - creative_imagination
    - productiveness
    - responsibility

analysis:
  load_data: true
  path_to_preprocessed_data: "../data/preprocessed"
  random_state: 42

  # In the final version, we do not use mpi4py and always use split_reps!!!
  use_mpi4py: false  # Change Backend to LOKY, if FALSE
  split_reps: true  # this makes only sense if use_mpi4py is False
  store_pred_and_true: true

  tests:
    sample: true
    sample_size: 200

  methods_to_apply:
    - select_samples
    - select_features
    - select_criterion
    - initial_info_log
    - drop_zero_variance_cols
    - create_pipeline
    - repeated_nested_cv
    - get_average_coefficients
    - process_all_shap_ia_values
    - store_analysis_results  # CAUTION

# for each combination, we will also use all samples and always compare it against the same samples using only pl
  feature_sample_combinations:
    # 1
    pl: [emotions, cocout, cocoesm, cocoms]
    srmc: [emotions, cocout, cocoesm, cocoms]
    sens: [zpid, cocoms]
    mac: [cocoesm]
    # 2  filter for "pl_" for comparisons
    pl_srmc: [emotions, cocout, cocoesm, cocoms]
    pl_sens: [zpid, cocoms]
    pl_srmc_sens: [cocoms]
    pl_mac: [cocoesm]
    # 3
    pl_srmc_mac: [cocoesm]
    # 4 all_in
    all_in: [cocoesm, cocout, cocoms, emotions, pia, zpid]

    #### Additional analysis ####
    # control analyses for pl_srmc_sens results
    pl_srmc_control: [cocoms] # only persons with sensing data
    srmc_control: [cocoms] # only persons with sensing data

    # control analysis without neuroticism and self-esteem
    # 1
    pl_nnse: [emotions, cocout, cocoesm, cocoms]
    # 2  filter for "pl_" for comparisons
    pl_srmc_nnse: [ emotions, cocout, cocoesm, cocoms ]
    pl_sens_nnse: [ zpid, cocoms ]
    pl_srmc_sens_nnse: [ cocoms ]
    pl_mac_nnse: [ cocoesm ]
    # 3
    pl_srmc_mac_nnse: [ cocoesm ]
    # 4 all_in
    all_in_nnse: [ cocoesm, cocout, cocoms, emotions, pia, zpid ]

    # Sensing with feature selection
    sens_fs: [zpid, cocoms]
    pl_sens_fs: [zpid, cocoms]
    pl_srmc_sens_fs: [ cocoms ]
    all_in_fs: [cocoesm, cocout, cocoms, emotions, pia, zpid]

  no_control_lst: ["pl", "srmc", "sens", "mac", "all_in"] # we do not run control analyses for these combinations

  params: # adjusted by SLURM
    prediction_model: elasticnet  # elasticnet, randomforestregressor
    crit: wb_state  # wb_state, wb_trait, etc
    feature_combination: pl_mac # pl, srmc, sens, mac, pl_srmc, pl_sens, pl_srmc_sens, pl_mac, pl_srmc_mac, all_in
    samples_to_include: all  # all, selected, control

  cv:
    num_inner_cv: 3  # 10
    verbose_inner_cv: 0
    num_outer_cv: 3 # 10
    num_reps: 3  # 10
    id_grouping_col: other_unique_id
    cache_pipe: false  # not improving performance
    warm_start: false  # not improving performance

  feature_selection:
    num_sensing_features: 21  # as number of srmc features

  crit_available: # not all criteria are available for all samples
    #state_wb: [cocoesm, cocout, cocoms, emotions, pia, zpid]
    #state_pa: [cocoesm, cocout, cocoms, emotions, pia]
    #state_na: [cocoesm, cocout, cocoms, emotions, pia]
    #trait_wb: [cocoesm, cocout, cocoms, pia, zpid]
    #trait_pa: [cocoesm, cocout, cocoms, pia, zpid]
    #trait_na: [cocoesm, cocout, cocoms, pia, zpid]
    wb_state: [ cocoesm, cocout, cocoms, emotions, pia, zpid ]
    pa_state: [ cocoesm, cocout, cocoms, emotions, pia ]
    na_state: [ cocoesm, cocout, cocoms, emotions, pia ]
    wb_trait: [ cocoesm, cocout, cocoms, pia, zpid ]
    pa_trait: [ cocoesm, cocout, cocoms, pia, zpid ]
    na_trait: [ cocoesm, cocout, cocoms, pia, zpid ]

  imputation:
    num_imputations: 5 # 5
    max_iter: 1 # 40
    conv_thresh: 0.05  # 0.05  only RFR
    tree_max_depth: 10  # only RFR
    percentage_of_features: 0.5  # only ENR
    n_features_thresh: 50  # only ENR
    sample_posterior: False  # only ENR, use PMM instead
    pmm_k: 5  # number of neighbors to consider for PMM
    country_grouping_col: "other_country"
    years_col: "other_years_of_participation"

  scoring_metric:
    inner_cv_loop:
      name: neg_mean_squared_error
    outer_cv_loop: # only for evaluation in the outer loop, not for fitting, all tested
      - r2
      - neg_mean_squared_error
      - spearman
      - pearson

  model_hyperparameters:
    elasticnet:  # verify
      model__regressor__alpha: [0.1, 1]
      model__regressor__l1_ratio: [0.5]
      #model__regressor__alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]
      #model__regressor__l1_ratio: [0, 0.1, 0.2, 0.3, 0.4, 0.4, 0.6, 0.7, 0.8, 0.9, 1]
      #model__regressor__max_iter: [ 1000, 10000 ]
      #model__regressor__tol: [0.1, 0.01, 0.001, 0.0001]
    randomforestregressor:
      model__regressor__max_depth: [ 4, 6 ]
      model__regressor__max_features: [ 0.2 ]
      #model__regressor__n_estimators: [ 100, 500 ]
      #model__regressor__max_features: [ 0.25, 0.5, 0.75]
      #model__regressor__max_depth: [4, 6, 8, 10, 12]
      #model__regressor__min_samples_split: [5, 10, 15, 20]

  parallelize:
    parallelize_shap: true
    shap_n_jobs: 1
    parallelize_inner_cv: true
    inner_cv_n_jobs: 1
    parallelize_shap_ia_values: true
    shap_ia_values_n_jobs: 1
    parallelize_imputation_runs: true # Cannot parallelize columns
    imputation_runs_n_jobs: 1
    joblib_backend: "loky"  # threading; for pc2, use threading, loky may crash in multi-node settings

  shap_ia_values:
    comp_shap_ia_values: false # true
    interaction_index: "k-SII"
    min_order: 0  # 0; min interaction order, always choose 0
    max_order: 2  # 3; max interaction order, one correspond to the normal SHAP values
    num_samples: 100  # 100

  output_path: "../results/local_tests"

  output_filenames:
    performance: 'cv_results'  # .json
    shap_values: 'shap_values'  # .pkl
    shap_ia_values_for_local: 'shap_ia_values_for_local' #.pkl
    shap_ia_values_for_cluster: 'shap_ia_values_for_cluster' #.pkl
    lin_model_coefs: 'lin_model_coefficients' # .pkl

postprocessing:
  methods:
    ##### Summarizing results
    #- merge_cluster_results
    #- merge_reps
    #- check_crit_dist
    ##### performance based
    #- process_cv_results
    #- process_lin_model_coefs
    #- condense_results
    #- create_descriptives
    #- create_cv_results_plots
    ##### shap based, may need to change "raw_results_path" and "processed_results_path"
    #- process_shap_values
    - create_shap_plots


  # Currently, because of the big amounts of data, we may have separated raw dirs
  # raw: cv: "../results/cluster_results_only_cv_raw" , shap:
  # proc: cv: "../results/cluster_results_only_cv_proc" , shap: "../results/cluster_results_shap_merged" or

  # "../results/results_merged_onlycv"
  raw_results_path: "../results/cluster_results_merged_2611"  # BASE RESULT DIR FOR RAW RESULTS  # shap or cv test_fs_shap

  # "C:/Users/lokal_o_haet01/Documents/git_repos/coco_wb_ml_code/results/  a) cluster_results_only_cv_proc" b) cluster_results_shap_merged
  processed_results_path: "C:/Users/lokal_o_haet01/Documents/git_repos/coco_wb_ml_code/results/cluster_results_shap_merged"  #"../results/cluster_results_only_cv_proc  # cluster_results_only_cv_proc"  # "# BASE RESULT DIR FOR PROCESSED RESULTS  # shap or cv


  #plots_base_dir: "../results/plots"
  #tables_base_dir: "../results/plots"
  merge_cluster_results:
    merge_folders: true
    source_1: "../results/res_js_pc2_2611"
    source_2: "../results/res_oh_pc2_2611"
    output_folder: "../results/cluster_results_merged_2611"

  shap_processing:
    merge_folders: true  # do merge folders from different cluster accounts
    source_1: "../results/cluster_results_shap_js"
    source_2: "../results/cluster_results_shap_oh"
    output_folder: "../results/cluster_results_shap_merged"

  metric: spearman


  significance_tests:
    output_path: "../results/significance_tests"
    alpha: .05
    metric: r2 # r2
    methods:
      - xxx

  plots:
    store_plots: true
    plots:
      - importance_plot
      - beeswarm_plot
    feature_combo_name_mapping:
      pl: "Personal" # "Person-level"
      srmc: "ESM"
      sens: "Sensing"
      mac: "Societal" # "Macro-level"
      pl_srmc: "Personal + ESM"
      pl_sens: "Personal + Sensing"
      pl_srmc_sens: "Personal + ESM + Sensing"
      pl_mac: "Personal + Societal"
      pl_srmc_mac: "Personal + ESM + Societal"

    cv_result_plot:
      crit: [ state_wb ]
      samples_to_include: [ selected ]

    shap_importance_plot:  # could define dpi, etc as well here

      # This should be lists
      prediction_model: [randomforestregressor]  # elasticnet, randomforestregressor
      crit: [state_wb]
      samples_to_include: [selected]

      num_to_display: 6

      # first_col: ["pl", "srmc", "sens", "mac"]
      # second_col: ["pl_srmc", "pl_sens", "pl_srmc_sens", "pl_mac"]
      # third_col: ["pl_srmc_mac"]
      first_col: ["pl", "srmc", "sens"]
      second_col: ["mac", "pl_srmc", "pl_sens"]
      third_col: ["pl_mac", "pl_srmc_sens", "pl_srmc_mac"]






