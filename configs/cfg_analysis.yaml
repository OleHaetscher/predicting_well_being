# Analysis config

load_data: true
path_to_preprocessed_data: "../data/preprocessed"  # TODO Could remove?
random_state: 42

# In the final version, we do not use mpi4py and always use split_reps!!!
use_mpi4py: false  # false   Change Backend to LOKY, if FALSE
split_reps: true  # true   # this makes only sense if use_mpi4py is False
store_pred_and_true: true  # true

tests:  # for testing purposes
  sample: true
  sample_size: 120

methods_to_apply:
  - select_data
  - initial_info_log
  - drop_zero_variance_cols
  - create_pipeline
  - repeated_nested_cv
  - get_average_coefficients
  - process_all_shap_ia_values
  - store_analysis_results  # CAUTION

feature_combinations:
  - pl
  - srmc
  - sens
  - mac

# for each combination, we will also use all samples and always compare it against the same samples using only pl
feature_sample_combinations:
  # 1
  pl: [emotions, cocout, cocoesm, cocoms]
  srmc: [emotions, cocout, cocoesm, cocoms]
  sens: [zpid, cocoms]
  mac: [cocoesm]
  # 2  filter for "pl_" for comparisons
  pl_srmc: [emotions, cocout, cocoesm, cocoms]
  pl_sens: [zpid, cocoms]
  pl_srmc_sens: [cocoms]
  pl_mac: [cocoesm]
  # 3
  pl_srmc_mac: [cocoesm]
  # 4 all_in
  all_in: [cocoesm, cocout, cocoms, emotions, pia, zpid]

  #### Additional analysis ####
  # control analyses for pl_srmc_sens results
  pl_srmc_control: [cocoms] # only persons with sensing data
  srmc_control: [cocoms] # only persons with sensing data

  # control analysis without neuroticism and self-esteem
  # 1
  pl_nnse: [emotions, cocout, cocoesm, cocoms]
  # 2  filter for "pl_" for comparisons
  pl_srmc_nnse: [ emotions, cocout, cocoesm, cocoms ]
  pl_sens_nnse: [ zpid, cocoms ]
  pl_srmc_sens_nnse: [ cocoms ]
  pl_mac_nnse: [ cocoesm ]
  # 3
  pl_srmc_mac_nnse: [ cocoesm ]
  # 4 all_in
  all_in_nnse: [ cocoesm, cocout, cocoms, emotions, pia, zpid ]

  # Sensing with feature selection
  sens_fs: [zpid, cocoms]
  pl_sens_fs: [zpid, cocoms]
  pl_srmc_sens_fs: [ cocoms ]
  all_in_fs: [cocoesm, cocout, cocoms, emotions, pia, zpid]

no_control_lst: ["pl", "srmc", "sens", "mac", "all_in"] # we do not run control analyses for these combinations

params: # adjusted by SLURM
  prediction_model: randomforestregressor  # elasticnet, randomforestregressor
  crit: wb_state  # wb_state, wb_trait, etc
  feature_combination: srmc # pl, srmc, sens, mac, pl_srmc, pl_sens, pl_srmc_sens, pl_mac, pl_srmc_mac, all_in
  samples_to_include: all  # all, selected, control

cv:
  num_inner_cv: 3  # 10
  verbose_inner_cv: 0
  num_outer_cv: 3 # 10
  num_reps: 3  # 10
  id_grouping_col: other_unique_id
  cache_pipe: false  # not improving performance
  warm_start: false  # not improving performance

feature_selection:
  num_sensing_features: 21  # as number of srmc features

crit_available: # not all criteria are available for all samples
  wb_state: [ cocoesm, cocout, cocoms, emotions, pia, zpid ]
  pa_state: [ cocoesm, cocout, cocoms, emotions, pia ]
  na_state: [ cocoesm, cocout, cocoms, emotions, pia ]
  wb_trait: [ cocoesm, cocout, cocoms, pia, zpid ]
  pa_trait: [ cocoesm, cocout, cocoms, pia, zpid ]
  na_trait: [ cocoesm, cocout, cocoms, pia, zpid ]

imputation:
  num_imputations: 5 # 5
  max_iter: 1 # 40
  conv_thresh: 0.05  # 0.05  only RFR
  tree_max_depth: 10  # only RFR
  percentage_of_features: 0.5  # only ENR
  n_features_thresh: 50  # only ENR
  sample_posterior: False  # only ENR, use PMM instead
  pmm_k: 5  # number of neighbors to consider for PMM
  country_grouping_col: "other_country"
  years_col: "other_years_of_participation"

scoring_metric:
  inner_cv_loop:
    name: neg_mean_squared_error
  outer_cv_loop: # only for evaluation in the outer loop, not for fitting, all tested
    - r2
    - neg_mean_squared_error
    - spearman
    - pearson

model_hyperparameters:
  elasticnet:  # verify
    model__regressor__alpha: [0.1, 1]
    model__regressor__l1_ratio: [0.5]
    #model__regressor__alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]
    #model__regressor__l1_ratio: [0, 0.1, 0.2, 0.3, 0.4, 0.4, 0.6, 0.7, 0.8, 0.9, 1]
    #model__regressor__max_iter: [ 1000, 10000 ]
    #model__regressor__tol: [0.1, 0.01, 0.001, 0.0001]
  randomforestregressor:
    model__regressor__max_depth: [ 4, 6 ]
    model__regressor__max_features: [ 0.2 ]
    #model__regressor__n_estimators: [ 100, 500 ]
    #model__regressor__max_features: [ 0.25, 0.5, 0.75]
    #model__regressor__max_depth: [4, 6, 8, 10, 12]
    #model__regressor__min_samples_split: [5, 10, 15, 20]

parallelize:
  parallelize_shap: true
  shap_n_jobs: 3
  parallelize_inner_cv: true
  inner_cv_n_jobs: 3
  parallelize_shap_ia_values: true
  shap_ia_values_n_jobs: 1
  parallelize_imputation_runs: true # Cannot parallelize columns
  imputation_runs_n_jobs: 1
  joblib_backend: "loky"  # threading; for pc2, use threading, loky may crash in multi-node settings

shap_ia_values:
  comp_shap_ia_values: false # true
  interaction_index: "k-SII"
  min_order: 0  # 0; min interaction order, always choose 0
  max_order: 2  # 3; max interaction order, one correspond to the normal SHAP values
  num_samples: 100  # 100

output_path: "../results/local_tests"

output_filenames:
  performance: 'cv_results'  # .json
  shap_values: 'shap_values'  # .pkl
  shap_ia_values_for_local: 'shap_ia_values_for_local' #.pkl
  shap_ia_values_for_cluster: 'shap_ia_values_for_cluster' #.pkl
  lin_model_coefs: 'lin_model_coefficients' # .pkl